pow <- function(x = 4, n = 3) {
x^n
}
pow()
cube <- function(x, n) {
x^3
}
cube(3)
x <- 1:10
if(x > 5) {
x <- 0
}
x
x <- 1:10
if(x > 0) {
x <- 0
}
x
x <- 1:10
if(x > 0) {
x <- 0
}
library(datasets)
data(iris)
iris
?iris
sepalmean=mean(iris[101:150,:])
sepalmean=mean(iris[101:150,])
sepalmean=mean(iris[101:150,1])
apply(iris[, 1:4], 2, mean)
sepalmean=mean(iris[1:150,1])
sepalmean=mean(iris[1:150,2])
sepalmean=mean(iris[1:150,3])
sepalmean=mean(iris[1:150,4])
library(datasets)
data(mtcars)
?mtcars
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
xx=mtcars
View(xx)
View(mtcars)
sapply(split(mtcars$mpg, mtcars$cyl), mean)
debug(ls)
ls
ls(1)
8
exit
quit
iris
iris
sapply(split(mtcars$hp, mtcars$cyl), mean)
209.21429 -82.63636
x <- rnorm(100)
hist(x)
x11
?x11
x11()
hist(x)
graphics.off()
x <- rnorm(100)
y <- x + rnorm(100)
par(las = 1)
plot(x, y)
par(las = 2)
plot(x, y)
par(las = 1)
par(las = 1)
plot(x, y)
x <- rnorm(100)
y <- x + rnorm(100)
plot(x, y)
x1 <- rnorm(10)
y1 <- rnorm(10)
points(x1, y1, col = "red")
pdf(file = "testRplot.pdf")
x <- rnorm(100)
hist(x)
dev.off()
library(lattice)
library(nlme)
xyplot(distance ~ age | Subject, data = Orthodont)
xyplot(distance ~ age | Subject, data = Orthodont, type = "b")
?gl
png()
points()
file()
axis()
png()
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(nlme)
png()
xyplot(weight ~ Time | Diet, BodyWeight)
plot(0, 0, main = substitute(theta))
packages.install("KernSmooth")
install.packages("packages.install("KernSmooth")
install.packages("KernSmooth")
library(KernSmooth)
load("~/Documents/Coursera/GettingAndCleaningData/Quizz3/Quizz3.RData")
View(mergedat)
mean(mergedat[mergedat[,12]=="High income: nonOECD"])
mean(mergedat[mergedat[,12]=="High income: nonOECD", 2])
mean(mergedat[mergedat[,12]=="High income: nonOECD", 2])
mergedat[, 12] == "High income: nonOECD"
boolvec<-mergedat[, 12] == "High income: nonOECD"
mean(mergedat[boolvec, 2])
?mean
mean(mergedat[boolvec, 2], na.rm=TRUE)
mean(as.numeric(mergedat[boolvec, 2]), na.rm=TRUE)
mean(as.numeric(mergedat[boolvec, 2]), na.rm=FALSE)
mean(as.numeric(mergedat[boolvec, 2]))
mergedat[,mean(x),by=Income.Group]
mergedat[,mean(Gross.domestic.product.2012),by=Income.Group]
summaryBy(Gross.domestic.product.2012~Income.Group, data=mergedat, FUN=c(mean))
library(doBy)
install.packages("doBy")
library(doBy)
summaryBy(Gross.domestic.product.2012~Income.Group, data=mergedat, FUN=c(mean))
mergedat1<-mergedat[, c(2,12)]
mergedat1[,2]<-as.numeric(mergedat[,2])
summaryBy(Gross.domestic.product.2012~Income.Group, data=mergedat1, FUN=c(mean))
View(mergedat1)
View(mergedat1)
View(mergedat)
View(mergedat)
mergedat1<-mergedat[, c(2,12)]
View(mergedat1)
View(mergedat1)
summaryBy(Gross.domestic.product.2012~Income.Group, data=mergedat1, FUN=c(mean))
View(mergedat1)
View(mergedat1)
mergedat1[,1]=as.numeric(mergedat1[,1])
View(mergedat1)
View(mergedat1)
View(mergedat)
View(mergedat)
mergedat1<-mergedat[, c(2,12)]
mergedat1[,1]=as.integer(mergedat1[,1])
View(mergedat1)
View(mergedat1)
View(mergedat)
View(mergedat)
View(mergedat1)
View(mergedat1)
View(mergedat)
View(mergedat)
View(mergedat1)
View(mergedat1)
View(mergedat1)
View(mergedat1)
View(mergedat)
View(mergedat)
View(mergedat)
View(mergedat)
View(mergedat1)
View(mergedat1)
View(mergedat)
View(mergedat)
mergedat1<-mergedat[, c(2,12)]
mergedat1[,1]=as.numeric.factor(mergedat1[,1])
as.numeric.factor <- function(x) {(as.numeric(levels(x))[x]}
as.numeric.factor <- function(x) {as.numeric(levels(x))[x]}
mergedat1[,1]=as.numeric.factor(mergedat1[,1])
View(mergedat)
View(mergedat)
View(mergedat1)
View(mergedat)
View(mergedat1)
View(mergedat)
summaryBy(Gross.domestic.product.2012~Income.Group, data=mergedat1, FUN=c(mean))
?is.na
mergedat1[,1]=(mergedat1[!is.na(mergedat1[,1]),1])
mergedat2<-(mergedat1[!is.na(mergedat1[,1]),])
summaryBy(Gross.domestic.product.2012~Income.Group, data=mergedat2, FUN=c(mean))
?cut
cutvec<-cut(mergedat2[,1], breaks=5)
cutvec
answ<-table( cutvec,  mergedat2[,12])
lev<-levels(cutvec)
cutvec<-cut(mergedat2[,1], breaks=5)
cut2fac=as.numeric.factor(cutvec)
cut2fac
cut2fac<-as.numeric.factor(cutvec)
cutvec<-cut(mergedat2[,1], breaks=5)
?table
asnw<-cbind(quartile=cutvec,mergedat2[,12])
asnw<-cbind(quartile=cutvec,income=mergedat2[,12])
asnw<-cbind(quartile=cutvec,income=mergedat2[,2])
View(asnw)
View(asnw)
View(mergedat2)
View(mergedat2)
res<-asnw[,1]==1 & asnw[,2]==4
sum(res)
save.image("~/Documents/Coursera/GettingAndCleaningData/Project/Project.RData")
savehistory("~/Documents/Coursera/GettingAndCleaningData/his.Rhistory")
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
library(lattice)
library(datasets)
data(airquality)
xyplot(Ozone ~ Wind | factor(Month), data = airquality)
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(lattice)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
print(p)
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
install.packages("ggplot2")
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(ggplot2)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
summary(data)
summary(airquality)
View(airquality)
View(airquality)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies, panel = panel.loess)
qplot(votes, rating, data = movies) + geom_smooth()
install.packages("caret")
install.packages("rpart")
install.packages("tree")
install.packages("randomForest")
install.packages("e1071")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("tree")
setwd("~/Documents/Coursera/DataScience/datasci_course_materials/assignment5")
data <- read.csv("seaflow_21min.csv")
summary(data)
View(data)
library(caret)
inTrain <- createDataPartition(y = data$pop,
+ ## the outcome data are needed
+ p = .5,
+ ## The percentage of data in the
+ ## training set
+ list = FALSE)
> ## The format of the results
>
> ## The output is a set of integers for the rows of Sonar
> ## that belong in the training set.
inTrain <- createDataPartition(y = data$pop, p = .5, list = FALSE)
training <- data[ inTrain,]
testing <- data[-inTrain,]
mean(data$tiome)
mean(data$time)
ggplot(data, aes(x=pe, y=chl_small, colour=pop))
ggplot(data, aes(x=pe, y=chl_small)
)
ggplot(data, aes(x=pe, y=chl_small, colour=pop))+ geom_point()
library(rpart)
model <- train(data$pop~, data)
model <- train(data$pop ~, data)
model <- train(pop ~, data)
?train
?rpart
model <- rpart(pop ~, data)
model <- rpart(data$pop ~, data)
model <- rpart(pop ~, data)
model <- rpart(pop ~, data=data)
model <- rpart(pop ~, data=train)
model <- rpart(pop ~, data=training)
model <- rpart(pop ~, data=training)
model <- rpart(pop ~  file_id+ time+ cell_id+ d1+ d2+ fsc_small+ fsc_perp+ fsc_big+ pe+ chl_small+ chl_big, data=training)
print(model)
Prediction <- predict(model, testing, type = "class")
Prediction
?predict
sum(testing$pop[-inTrain]==Prediction)
realClass<-testing$pop[-inTrain]
sum(realClass==Prediction)
9492/36171
library(randomforest)
library(randomForest)
model <- randomForest(pop ~  file_id+ time+ cell_id+ d1+ d2+ fsc_small+ fsc_perp+ fsc_big+ pe+ chl_small+ chl_big, data=training)
Prediction <- predict(model, testing, type = "class")
sum(testing$pop[-inTrain]==Prediction)
9398/36172
importance(model)
model <- svm(fol, data=trainingdata)
library(e1071)
model <- svm(fol, data=trainingdata)
?svm
model <- svm(pop ~  file_id+ time+ cell_id+ d1+ d2+ fsc_small+ fsc_perp+ fsc_big+ pe+ chl_small+ chl_big, data=training)
Prediction <- predict(model, testing, type = "class")
sum(testing$pop[-inTrain]==Prediction)
9389/36172
table(pred = Prediction, true = testing$pop)
model <- randomForest(pop ~  file_id+ time+ cell_id+ d1+ d2+ fsc_small+ fsc_perp+ fsc_big+ pe+ chl_small+ chl_big, data=training)
Prediction <- predict(model, testing, type = "class")
sum(testing$pop[-inTrain]==Prediction)
table(pred = Prediction, true = testing$pop)
model <- rpart(pop ~  file_id+ time+ cell_id+ d1+ d2+ fsc_small+ fsc_perp+ fsc_big+ pe+ chl_small+ chl_big, data=training)
Prediction <- predict(model, testing, type = "class")
table(pred = Prediction, true = testing$pop)
539+183+1407
642+149+760
save.image("~/Documents/Coursera/DataScience/datasci_course_materials/assignment5/workspace.RData")
savehistory("~/Documents/Coursera/DataScience/datasci_course_materials/assignment5/history.Rhistory")
